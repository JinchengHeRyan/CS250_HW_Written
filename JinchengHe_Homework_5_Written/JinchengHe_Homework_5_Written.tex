\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=1in]{geometry}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{arydshln}
\usepackage{mathtools}
\usepackage{cases}
\usepackage{listings}
\usepackage[numbered]{mcode}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{subfigure}

\usepackage{blindtext}
\usepackage{amssymb}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}

\urlstyle{same}

%\newtheorem{theorem}{Theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\title{CS 250 - Computer Architecture \\ Homework 5 Written}
\author{Jincheng He Email: jincheng.he@dukekunshan.edu.cn}
\date{December 13, 2021}

\begin{document}

    \maketitle


    \section{Q1. Cache policies}
    \textbf{Why are write-back caches usually also write-allocate?}

    The advantage of write-back caches is when writing to a block for multiple times, it can stay in cache, only need to be written to main memory when it is going to be replaced.
    So if the block is loaded on a write miss, if there is any subsequent writes, it can still stay in cache instead of going to the main memory, which can save time.


    \section{Q2. Cache performance}
    \textbf{Your L1 data cache has an access latency of 1ns, and your L2 cache has an access latency of 10ns. Assume that 90\% of your L1 accesses are hits, and assume that 100\% of your L2 accesses are hits. What is the average memory latency as seen by the processor core?}

    The equation is as the following:
    \begin{equation*}
        \text{avg\_time} = 0.9 \times 1\text{ns} + 0.1 \times 1 \times 10\text{ns} = 1.9\text{ns}
    \end{equation*}

    So the average time is \textbf{1.9 ns}.


    \section{Q3. Virtual memory layout}
    \textbf{You have a 64-bit machine and you bought 16GB of physical memory. Pages are 256KB.}
    \begin{enumerate}
        \item[(a)] \textbf{How many virtual pages do you have per process?}

        The answer is as the following:
        \begin{equation*}
            \frac{2^{64}}{256\times 2^{10}} = \frac{2^{64}}{2^{18}} = 2^{46}
        \end{equation*}

        So there should be $2^{46}$ virtual pages.

        \item[(b)] \textbf{How many physical pages do you have?}

        There are in total $16\times 2^{30} = 2^{34}$ Bytes of physical memory. So the number of physical pages is $\frac{2^{34}}{256\times 2^{10}} = 2^{16}$.

        \item[(c)] \textbf{In the translation from a virtual address to a physical address, how manny bits of VPN are you mapping to how many bits of PPN (assuming you have just enough bits in the physical address for the amount of physical RAM present)?}

        Both the physical page offset bits and virtual page offset bits are $\log_2 \left( 256\times 2^{10} \right) = 18$. Since for physical address, it needs 34 bits, so for PPN, it needs $34 - 18 = 16$ bits. For VPN, it needs $64 - 18 = 46$ bits.

        \item[(d)] \textbf{How big does a page table entry (PTE) need to be to hold just a single PPN?}

        Since each PTE only need to hold just a single PPN. Because there are in total $2^{16}$ physical pages, we for each PTE, it needs 16 bits, which is 2 Bytes.

        \item[(e)] \textbf{How big would a flat page table be for a single process, assuming PTEs are the size computed in part (d)?}

        Since there would be in total $2^{46}$ virtual pages, and for each page, it needs 16 bits, which is 2 Bytes, so it needs $2^{47}$ Bytes, which is 128TB.

        \item[(f)] \textbf{Why does the answer above suggest that a "flat page table" isn't going to work for a 64-bit system like this? Research the concept of a \textit{multi-level page table}, and briefly define it here. Why could such a data structure be much smaller than a flat page table?}

        Using 128 TB to store the page table is unacceptable. Multi-level paging is a paging scheme which consists of two or more levels of page tables in a hierarchical manner. This kind of method can greatly lower the table size. Here is an example. For 2-level page table, if using the first 10 bits to index to the first level page table, and use the second 10 bits to index to the second level page table. In this case, (assume PTE is 4 bytes), the size should be $2^{10}\times 4 + 2^{10}\times 4 = 8\text{KB}$. However, for a flat page table, the size should be $2^{20} \times 4 = 4\text{MB}$, which differs a lot.

        \item[(g)] \textbf{Does a TLB miss always lead to a page fault? Why or why not?}

        No it does not. When there is a TLB miss, it only means that we cannot find the page frame number inside the TLB. Then we should go to the page table to find out, but it does not necessarily lead to a page fault. Page fault means the page accessed by a program is not present in physical memory.

    \end{enumerate}


\end{document}