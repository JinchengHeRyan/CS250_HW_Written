\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=1in]{geometry}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{arydshln}
\usepackage{mathtools}
\usepackage{cases}
\usepackage{listings}
\usepackage[numbered]{mcode}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{subfigure}

\usepackage{blindtext}
\usepackage{amssymb}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}

\urlstyle{same}

%\newtheorem{theorem}{Theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\title{CS 250 - Computer Architecture \\ Homework 5 Written}
\author{Jincheng He Email: jincheng.he@dukekunshan.edu.cn}
\date{December 13, 2021}

\begin{document}

    \maketitle


    \section{Q1. Cache policies}
    \textbf{Why are write-back caches usually also write-allocate?}

    The advantage of write-back caches is when writing to a block for multiple times, it can stay in cache, only need to be written to main memory when it is going to be replaced.
    So if the block is loaded on a write miss, if there is any subsequent writes, it can still stay in cache instead of going to the main memory, which can save time.


    \section{Q2. Cache performance}
    \textbf{Your L1 data cache has an access latency of 1ns, and your L2 cache has an access latency of 10ns. Assume that 90\% of your L1 accesses are hits, and assume that 100\% of your L2 accesses are hits. What is the average memory latency as seen by the processor core?}

    The equation is as the following:
    \begin{equation*}
        \text{avg\_time} = 0.9 \times 1\text{ns} + 0.1 \times 1 \times 10\text{ns} = 1.9\text{ns}
    \end{equation*}

    So the average time is \textbf{1.9 ns}.


    \section{Q3. Virtual memory layout}
    \textbf{You have a 64-bit machine and you bought 16GB of physical memory. Pages are 256KB.}
    \begin{enumerate}
        \item[(a)] \textbf{How many virtual pages do you have per process?}

        The answer is as the following:
        \begin{equation*}
            \frac{2^{64}}{256\times 2^{10}} = \frac{2^{64}}{2^{18}} = 2^{46}
        \end{equation*}

        So there should be $2^{46}$ virtual pages.

        \item[(b)] \textbf{How many physical pages do you have?}

        There are in total $16\times 2^{30} = 2^{34}$ Bytes of physical memory. So the number of physical pages is $\frac{2^{34}}{256\times 2^{10}} = 2^{16}$.

        \item[(c)] \textbf{In the translation from a virtual address to a physical address, how manny bits of VPN are you mapping to how many bits of PPN (assuming you have just enough bits in the physical address for the amount of physical RAM present)?}

        Both the physical page offset bits and virtual page offset bits are $\log_2 \left( 256\times 2^{10} \right) = 18$. Since for physical address, it needs 34 bits, so for PPN, it needs $34 - 18 = 16$ bits. For VPN, it needs $64 - 18 = 46$ bits.

        \item[(d)] \textbf{How big does a page table entry (PTE) need to be to hold just a single PPN?}


    \end{enumerate}


\end{document}